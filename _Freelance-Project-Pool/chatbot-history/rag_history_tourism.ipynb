{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG System for Historical Tourism Q&A\n",
        "\n",
        "Goal: Build an end-to-end RAG pipeline integrating MySQL (structured data), Qdrant (vector DB), and an LLM generator. The system returns cited, grounded answers for history + travel queries.\n",
        "\n",
        "Stack: Python, MySQL, Qdrant, Sentence-Transformers embeddings, OpenAI (optional) for generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: installs (skip if already installed)\n",
        "%pip -q install -r requirements.txt\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\".env\", override=True)\n",
        "load_dotenv(\"ENV.example\", override=False)\n",
        "\n",
        "MYSQL_HOST = os.getenv(\"MYSQL_HOST\", \"localhost\")\n",
        "MYSQL_PORT = int(os.getenv(\"MYSQL_PORT\", 3306))\n",
        "MYSQL_USER = os.getenv(\"MYSQL_USER\", \"root\")\n",
        "MYSQL_PASSWORD = os.getenv(\"MYSQL_PASSWORD\", \"\")\n",
        "MYSQL_DATABASE = os.getenv(\"MYSQL_DATABASE\", \"rag_history_tourism\")\n",
        "\n",
        "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
        "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
        "QDRANT_COLLECTION = os.getenv(\"QDRANT_COLLECTION\", \"rag_history_tourism\")\n",
        "\n",
        "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
        "\n",
        "print({\n",
        "    \"mysql\": f\"{MYSQL_USER}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DATABASE}\",\n",
        "    \"qdrant\": QDRANT_URL,\n",
        "    \"collection\": QDRANT_COLLECTION,\n",
        "    \"embedding_model\": EMBEDDING_MODEL,\n",
        "    \"openai_model\": OPENAI_MODEL,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to MySQL and create schema + seed data\n",
        "import mysql.connector as mysql\n",
        "import pandas as pd\n",
        "\n",
        "conn = mysql.connect(\n",
        "    host=MYSQL_HOST,\n",
        "    port=MYSQL_PORT,\n",
        "    user=MYSQL_USER,\n",
        "    password=MYSQL_PASSWORD,\n",
        ")\n",
        "conn.autocommit = True\n",
        "cur = conn.cursor()\n",
        "cur.execute(f\"CREATE DATABASE IF NOT EXISTS {MYSQL_DATABASE} CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\")\n",
        "cur.close()\n",
        "conn.close()\n",
        "\n",
        "conn = mysql.connect(\n",
        "    host=MYSQL_HOST,\n",
        "    port=MYSQL_PORT,\n",
        "    user=MYSQL_USER,\n",
        "    password=MYSQL_PASSWORD,\n",
        "    database=MYSQL_DATABASE,\n",
        ")\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS places (\n",
        "  id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "  name VARCHAR(255) NOT NULL,\n",
        "  country VARCHAR(128),\n",
        "  city VARCHAR(128),\n",
        "  lat DOUBLE,\n",
        "  lon DOUBLE,\n",
        "  description TEXT,\n",
        "  url VARCHAR(512)\n",
        ") ENGINE=InnoDB;\n",
        "\"\"\")\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS events (\n",
        "  id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "  place_id INT,\n",
        "  title VARCHAR(255) NOT NULL,\n",
        "  year_start INT,\n",
        "  year_end INT,\n",
        "  summary TEXT,\n",
        "  source VARCHAR(512),\n",
        "  FOREIGN KEY (place_id) REFERENCES places(id) ON DELETE SET NULL\n",
        ") ENGINE=InnoDB;\n",
        "\"\"\")\n",
        "\n",
        "# Minimal seed data: can expand later\n",
        "places = [\n",
        "    (\"Hoan Kiem Lake\", \"Vietnam\", \"Hanoi\", 21.0285, 105.8542, \"Historic lake in the Old Quarter, legend of the returned sword.\", \"https://en.wikipedia.org/wiki/Ho%C3%A0n_Ki%E1%BA%BFm_Lake\"),\n",
        "    (\"Hue Imperial City\", \"Vietnam\", \"Hue\", 16.4637, 107.5909, \"Former imperial capital with Nguyen dynasty citadel.\", \"https://en.wikipedia.org/wiki/Imperial_City_of_Hu%E1%BA%BF\"),\n",
        "]\n",
        "cur.executemany(\n",
        "    \"INSERT INTO places (name, country, city, lat, lon, description, url) VALUES (%s,%s,%s,%s,%s,%s,%s)\",\n",
        "    places,\n",
        ")\n",
        "\n",
        "cur.execute(\"SELECT id, name FROM places\")\n",
        "place_map = {name: pid for (pid, name) in cur.fetchall()}\n",
        "\n",
        "events = [\n",
        "    (place_map[\"Hoan Kiem Lake\"], \"Legend of the Returned Sword\", 1428, 1428, \"L\u001b0\u0001fi th\u0001b0\u0001d\u0001b0 Tr\u001ea n\u0001ea Hung D\u001ea o legend: Emperor L\u001ea L\u001ee i returned the divine sword to the Golden Turtle God at the lake.\", \"https://en.wikipedia.org/wiki/Ho%C3%A0n_Ki%E1%BA%BFm_Lake\"),\n",
        "    (place_map[\"Hue Imperial City\"], \"Nguyen Dynasty Capital\", 1802, 1945, \"Hue served as the imperial capital of the Nguyen dynasty, with significant architectural and cultural heritage.\", \"https://en.wikipedia.org/wiki/Imperial_City_of_Hu%E1%BA%BF\"),\n",
        "]\n",
        "cur.executemany(\n",
        "    \"INSERT INTO events (place_id, title, year_start, year_end, summary, source) VALUES (%s,%s,%s,%s,%s,%s)\",\n",
        "    events,\n",
        ")\n",
        "conn.commit()\n",
        "\n",
        "cur.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"Seeded MySQL with sample places and events.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build embeddings and ingest into Qdrant\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http import models as qmodels\n",
        "\n",
        "# Fetch documents from MySQL\n",
        "conn = mysql.connect(\n",
        "    host=MYSQL_HOST,\n",
        "    port=MYSQL_PORT,\n",
        "    user=MYSQL_USER,\n",
        "    password=MYSQL_PASSWORD,\n",
        "    database=MYSQL_DATABASE,\n",
        ")\n",
        "cur = conn.cursor(dictionary=True)\n",
        "cur.execute(\"\"\"\n",
        "SELECT e.id AS event_id, p.id AS place_id, p.name AS place_name, p.country, p.city, p.lat, p.lon,\n",
        "       e.title, e.year_start, e.year_end, e.summary, COALESCE(e.source, p.url) AS source\n",
        "FROM events e LEFT JOIN places p ON e.place_id = p.id\n",
        "ORDER BY e.id ASC\n",
        "\"\"\")\n",
        "rows = cur.fetchall()\n",
        "cur.close(); conn.close()\n",
        "\n",
        "# Prepare texts\n",
        "def format_doc(r):\n",
        "    yrs = f\"{r['year_start']}\" if r['year_end'] in (None, 0, r['year_start']) else f\"{r['year_start']}–{r['year_end']}\"\n",
        "    loc = \", \".join([x for x in [r['place_name'], r['city'], r['country']] if x])\n",
        "    return f\"{r['title']} ({yrs}) at {loc}. {r['summary']}\"\n",
        "\n",
        "texts = [format_doc(r) for r in rows]\n",
        "metadatas = rows\n",
        "\n",
        "# Embeddings\n",
        "embedder = SentenceTransformer(EMBEDDING_MODEL)\n",
        "embeddings = embedder.encode(texts, normalize_embeddings=True)\n",
        "\n",
        "# Qdrant client and collection\n",
        "qdrant = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
        "\n",
        "if QDRANT_COLLECTION not in [c.name for c in qdrant.get_collections().collections]:\n",
        "    qdrant.recreate_collection(\n",
        "        collection_name=QDRANT_COLLECTION,\n",
        "        vectors_config=qmodels.VectorParams(size=len(embeddings[0]), distance=qmodels.Distance.COSINE),\n",
        "    )\n",
        "\n",
        "# Upsert points\n",
        "from uuid import uuid4\n",
        "payloads = metadatas\n",
        "qdrant.upsert(\n",
        "    collection_name=QDRANT_COLLECTION,\n",
        "    points=[\n",
        "        qmodels.PointStruct(\n",
        "            id=str(uuid4()),\n",
        "            vector=emb.tolist(),\n",
        "            payload=payload,\n",
        "        )\n",
        "        for emb, payload in zip(embeddings, payloads)\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(f\"Ingested {len(payloads)} documents into Qdrant collection '{QDRANT_COLLECTION}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retriever and generator with citations\n",
        "from typing import List, Dict\n",
        "\n",
        "TOP_K = 5\n",
        "\n",
        "\n",
        "def retrieve(query: str, k: int = TOP_K) -> List[Dict]:\n",
        "    q_emb = embedder.encode([query], normalize_embeddings=True)[0]\n",
        "    search = qdrant.search(\n",
        "        collection_name=QDRANT_COLLECTION,\n",
        "        query_vector=q_emb.tolist(),\n",
        "        limit=k,\n",
        "        with_payload=True,\n",
        "        with_vectors=False,\n",
        "        score_threshold=None,\n",
        "    )\n",
        "    docs = []\n",
        "    for point in search:\n",
        "        payload = point.payload or {}\n",
        "        payload[\"score\"] = float(point.score)\n",
        "        docs.append(payload)\n",
        "    return docs\n",
        "\n",
        "\n",
        "def render_context(docs: List[Dict]) -> str:\n",
        "    lines = []\n",
        "    for d in docs:\n",
        "        title = d.get(\"title\") or d.get(\"place_name\")\n",
        "        source = d.get(\"source\") or d.get(\"url\") or \"\"\n",
        "        city = d.get(\"city\") or \"\"\n",
        "        country = d.get(\"country\") or \"\"\n",
        "        yrs = f\"{d.get('year_start')}\" if (not d.get('year_end') or d.get('year_end') == d.get('year_start')) else f\"{d.get('year_start')}–{d.get('year_end')}\"\n",
        "        line = f\"- {title} ({yrs}), {city}, {country}. Source: {source}\"\n",
        "        lines.append(line)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# Simple generation using OpenAI if available, else a rule-based fallback\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n",
        "except Exception:\n",
        "    openai_client = None\n",
        "\n",
        "\n",
        "def generate_answer(query: str, docs: List[Dict]) -> str:\n",
        "    context = \"\\n\".join(\n",
        "        [\n",
        "            f\"Title: {d.get('title')} | Place: {d.get('place_name')}, {d.get('city')}, {d.get('country')} | Years: {d.get('year_start')}-{d.get('year_end')}\\nSummary: {d.get('summary')}\\nSource: {d.get('source') or d.get('url') or ''}\"\n",
        "            for d in docs\n",
        "        ]\n",
        "    )\n",
        "    system = (\n",
        "        \"You are a factual travel history assistant. Use only the provided CONTEXT to answer. \"\n",
        "        \"Cite sources inline as [n] and add a 'Sources' section mapping [n] to URLs. If the answer is not in context, say you don't know.\"\n",
        "    )\n",
        "\n",
        "    if openai_client:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": f\"CONTEXT:\\n{context}\\n\\nQUESTION: {query}\"},\n",
        "        ]\n",
        "        try:\n",
        "            resp = openai_client.chat.completions.create(\n",
        "                model=OPENAI_MODEL,\n",
        "                messages=messages,\n",
        "                temperature=0.2,\n",
        "            )\n",
        "            return resp.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            print(\"OpenAI error:\", e)\n",
        "\n",
        "    # Fallback: extractive style summary\n",
        "    answer_lines = [\n",
        "        \"Based on available context:\",\n",
        "    ]\n",
        "    for i, d in enumerate(docs, start=1):\n",
        "        src = d.get(\"source\") or d.get(\"url\") or \"\"\n",
        "        yrs = f\"{d.get('year_start')}\" if (not d.get('year_end') or d.get('year_end') == d.get('year_start')) else f\"{d.get('year_start')}-{d.get('year_end')}\"\n",
        "        answer_lines.append(\n",
        "            f\"[{i}] {d.get('title')} in {d.get('place_name')}, {d.get('city')}, {d.get('country')} ({yrs}): {d.get('summary')}\"\n",
        "        )\n",
        "        if src:\n",
        "            answer_lines.append(f\"Source: {src}\")\n",
        "    if not docs:\n",
        "        answer_lines.append(\"No matching context found.\")\n",
        "    return \"\\n\".join(answer_lines)\n",
        "\n",
        "\n",
        "# Convenience wrapper\n",
        "\n",
        "def ask(query: str, k: int = 5) -> str:\n",
        "    docs = retrieve(query, k=k)\n",
        "    print(\"Top documents:\\n\" + render_context(docs))\n",
        "    print(\"\\n---\\n\")\n",
        "    return generate_answer(query, docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo\n",
        "query = \"Lịch sử và gợi ý tham quan quanh Hồ Hoàn Kiếm?\"\n",
        "print(ask(query, k=3))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
